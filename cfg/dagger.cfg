[DEFAULT]

alg = dagger
continue_training = True
# learning parameters
batch_size = 20
buffer_size = 10000
updates_per_step = 300
seed = 11
actor_lr = 1e-3

n_train_episodes = 401
beta_coeff = 0
test_interval = 100
n_test_episodes = 3

# architecture parameters
k = 5
hidden_size = 32
gamma = 0.99
tau = 0.5

# env parameters
# env = FlockingRelative-v0
# transfer_env_from=FlockingRelativeST-v0
# env = FlockingObstacle-v0
env = FlockingLeader-v0
v_max = 20.0
comm_radius = 7.0


n_agents = 20

n_actions = 2
n_states = 6
debug = True
header = reward
dt = 0.01


max_accel=1000
max_state_value=10000
max_velocity=20

[test]
# test only! use GT to get the BM scores
test_gt=False 
k = 5
transfer_test=False
# fname = dagger_obs_k3
fname = dagger_k5_leader